{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = np.loadtxt('/Users/babburi/datasets/HAR/train/X_train.txt')\n",
    "train_y = np.loadtxt('/Users/babburi/datasets/HAR/train/y_train.txt')\n",
    "train_y = np.eye(6)[train_y.astype('int')-1] # one-hot encoding\n",
    "test_x = np.loadtxt('/Users/babburi/datasets/HAR/test/X_test.txt')\n",
    "test_y = np.loadtxt('/Users/babburi/datasets/HAR/test/y_test.txt')\n",
    "test_y = np.eye(6)[test_y.astype('int')-1]\n",
    "\n",
    "seed = 222\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(train_x)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(train_y)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(test_x)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, 561], name='x')\n",
    "y = tf.placeholder('float', [None, 6], name='y')\n",
    "def train_softmax(x):\n",
    "    W = tf.Variable(tf.zeros([561, 6]), name='weights')\n",
    "    b = tf.Variable(tf.zeros([6]), name='bias')\n",
    "    lr = 0.25\n",
    "    prediction = tf.nn.softmax(tf.matmul(x, W) + b, name='op_predict')\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr).minimize(cost)\n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    saver = tf.train.Saver()\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(1000):\n",
    "        loss = 0\n",
    "        _, c = sess.run([optimizer, cost], feed_dict = {x: train_x, y: train_y})\n",
    "        loss += c\n",
    "        if (epoch % 100 == 0 and epoch != 0):\n",
    "            print('Epoch', epoch, 'completed out of', 1000, 'Training loss:', loss)\n",
    "    correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name='op_accuracy')\n",
    "    \n",
    "    print('Test set Accuracy:', sess.run(accuracy, feed_dict = {x: test_x, y: test_y}))\n",
    "    \n",
    "    saver.save(sess,'har_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 completed out of 1000 Training loss: 1.27441370487\n",
      "Epoch 200 completed out of 1000 Training loss: 1.20002996922\n",
      "Epoch 300 completed out of 1000 Training loss: 1.16756367683\n",
      "Epoch 400 completed out of 1000 Training loss: 1.15461301804\n",
      "Epoch 500 completed out of 1000 Training loss: 1.14508366585\n",
      "Epoch 600 completed out of 1000 Training loss: 1.13759946823\n",
      "Epoch 700 completed out of 1000 Training loss: 1.13134491444\n",
      "Epoch 800 completed out of 1000 Training loss: 1.12595498562\n",
      "Epoch 900 completed out of 1000 Training loss: 1.12121534348\n",
      "Test set Accuracy: 0.945707\n"
     ]
    }
   ],
   "source": [
    "train_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
